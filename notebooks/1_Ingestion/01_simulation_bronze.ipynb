{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0bb0ce58-5bb3-421a-a14c-5de5a7100095",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Archivo optimizado para la simulación de los eventos de compra de botellas de agua en Medellín"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cc2619f-dbfc-43e8-80ae-ba8c6b8b3075",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PASO 1: Imports & Config\n",
    "import json, random, uuid, time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import pyarrow\n",
    "from scipy.stats import truncnorm\n",
    "from numpy.random import poisson\n",
    "from shapely.validation import make_valid\n",
    "import numpy as np\n",
    "\n",
    "cfg      = json.loads(Path(\"/Workspace/Users/danielale22rojas@gmail.com/medellin-bigdata-poc/notebooks/1_Ingestion/sim_config.json\").read_text()) # Cambiar el nombre de usuario antes de ejecutar\n",
    "base     = Path(cfg[\"base_path\"])\n",
    "paths    = cfg[\"paths\"]\n",
    "interval = cfg[\"interval_seconds\"]\n",
    "qty_min, qty_max = cfg[\"quantity_range\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb31f502-a5ad-4ab9-a80b-0bf60f43d982",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PASO 2: Carga de insumos\n",
    "gdf_neigh = gpd.read_parquet(base/paths[\"neighborhoods\"])       # barrios\n",
    "mask_geom = gpd.read_parquet(base/paths[\"city_mask\"]).geometry.iloc[0]  # contorno Medellín\n",
    "df_cust   = pd.read_parquet(base/paths[\"customers\"])            # clientes\n",
    "df_emp    = pd.read_parquet(base/paths[\"employees\"])            # empleados\n",
    "# print(f\"✅ Barrios: {len(gdf_neigh)} | Clientes: {len(df_cust)} | Empleados: {len(df_emp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37eea6c5-c432-49dc-96a3-795c88b04c2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Aplicamos la funcion para corregir la geometría\n",
    "gdf_neigh[\"geometry\"] = gdf_neigh[\"geometry\"].apply(make_valid)\n",
    "\n",
    "# Primero corregimos el nombre\n",
    "gdf_neigh.loc[gdf_neigh[\"NOMBRE\"].isna(), \"NOMBRE\"] = \"ARANJUEZ\"\n",
    "\n",
    "# Luego disolvemos por el nombre\n",
    "gdf_neigh = gdf_neigh.dissolve(by=\"NOMBRE\", as_index=False)\n",
    "\n",
    "# Removemos la palabra corregimiento de los nombres\n",
    "gdf_neigh['NOMBRE'] = gdf_neigh['NOMBRE'].str.replace('CORREGIMIENTO DE ', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0a0a5a4-ba0b-4832-8e15-c0627cc00daf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Diccionario en MAYÚSCULAS (transcribir del DANE)\n",
    "poblacion = {\n",
    "    \"POPULAR\": 120000,\n",
    "    \"SANTA CRUZ\": 100000,\n",
    "    \"MANRIQUE\": 150000,\n",
    "    \"ARANJUEZ\": 110000,\n",
    "    \"CASTILLA\": 140000,\n",
    "    \"DOCE DE OCTUBRE\": 130000,\n",
    "    \"ROBLEDO\": 160000,\n",
    "    \"VILLA HERMOSA\": 115000,\n",
    "    \"BUENOS AIRES\": 125000,\n",
    "    \"LA CANDELARIA\": 90000,\n",
    "    \"LAURELES ESTADIO\": 95000,\n",
    "    \"LA AMÉRICA\": 110000,\n",
    "    \"SAN JAVIER\": 145000,\n",
    "    \"EL POBLADO\": 80000,\n",
    "    \"GUAYABAL\": 85000,\n",
    "    \"BELÉN\": 155000,\n",
    "    \"SAN SEBASTIÁN DE PALMITAS\": 20000,\n",
    "    \"SAN CRISTÓBAL\": 50000,\n",
    "    \"ALTAVISTA\": 30000,\n",
    "    \"SAN ANTONIO DE PRADO\": 60000,\n",
    "    \"SANTA ELENA\": 40000\n",
    "}\n",
    "\n",
    "# Convertir NOMBRE a mayúsculas y mapear población\n",
    "# gdf_neigh[\"NOMBRE\"] = gdf_neigh[\"NOMBRE\"].str.upper()\n",
    "gdf_neigh[\"poblacion\"] = gdf_neigh[\"NOMBRE\"].map(poblacion)\n",
    "\n",
    "# Verificar si hay nulos (barrios sin población asignada)\n",
    "# print(gdf_neigh[gdf_neigh[\"poblacion\"].isna()][[\"NOMBRE\"]]) # Debe quedar nulo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e531e04f-757c-4991-ae72-be20e6bb2056",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gdf_neigh.sample(1, weights=\"poblacion\").iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ac75e42-b38b-4488-bfc6-9d9a38f17e45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PASO 3: Funciones de muestreo y generación de evento\n",
    "def sample_point(poly):\n",
    "    minx,miny,maxx,maxy = poly.bounds\n",
    "    while True:\n",
    "        p = Point(random.uniform(minx, maxx), random.uniform(miny, maxy))\n",
    "        if poly.contains(p) and mask_geom.contains(p):\n",
    "            return p\n",
    "\n",
    "# Como usamos una distribución gausiana truncada, debemos definir los parametros \n",
    "# Parámetros de la distribución truncada\n",
    "# mu = 25      # número promedio de compras por simulación\n",
    "# sigma = 10   # dispersión\n",
    "# min_val = qty_min  # mínimo número de compras por intervalo\n",
    "# max_val = qty_max # máximo aceptado\n",
    "\n",
    "# # Convertir a valores estandarizados\n",
    "# min_val = (min_val - mu) / sigma\n",
    "# max_val = (max_val - mu) / sigma\n",
    "\n",
    "def gen_event():\n",
    "    # La asiganción de los barrios segun los pesos de la poblacion\n",
    "    b  = gdf_neigh.sample(1, weights=\"poblacion\").iloc[0]\n",
    "    pt = sample_point(b.geometry)\n",
    "    # Generar cantidad de productos (ej. Poisson proporcional a la población)\n",
    "    lam = b[\"poblacion\"] / 5000   # escala de λ\n",
    "    return {\n",
    "      \"order_id\":          str(uuid.uuid4()),\n",
    "      \"date\":              datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"),\n",
    "      \"customer_id\":       int(df_cust.customer_id.sample(1).iloc[0]),\n",
    "      \"employee_id\":       int(df_emp.employee_id.sample(1).iloc[0]),\n",
    "      # \"quantity_products\": int(truncnorm(min_val, max_val, loc=mu, scale=sigma).rvs()),\n",
    "      \"quantity_products\":  np.random.poisson(lam=max(5, lam)),\n",
    "      \"latitude\":          pt.y,\n",
    "      \"longitude\":         pt.x,\n",
    "      \"neighborhood\":      b[\"NOMBRE\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6ac7602-6eb5-411a-92b9-5e91fd63ed5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PASO 4: Preparar carpeta timestamp\n",
    "ts      = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_dir = base/paths[\"output_dir\"]/ts\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(\"▶️ Carpeta de simulación:\", out_dir.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "176db9e7-edb8-42d3-aee0-3973a2968a5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PASO 5 optimizada para prueba rápida:\n",
    "# Defninimos el número de eventos a generar como una variable aleatoria con distribución normal truncada\n",
    "\n",
    "# # Parámetros de la distribución truncada\n",
    "# mu2 = 40      # número promedio de compras por simulación\n",
    "# sigma2 = 25   # dispersión\n",
    "# min_val2 = 0  # mínimo número de compras por intervalo\n",
    "# max_val2 = 70 # máximo aceptado\n",
    "\n",
    "# # Convertir a valores estandarizados\n",
    "# a = (min_val2 - mu2) / sigma2\n",
    "# b = (max_val2 - mu2) / sigma2\n",
    "# N = int(truncnorm(a, b, loc=mu2, scale=sigma2).rvs())\n",
    "\n",
    "# Simular con distribución Poisson\n",
    "N = poisson(lam=30)\n",
    "\n",
    "# Simular con uniforme\n",
    "# N = random.randint(0, 30)\n",
    "\n",
    "# Corremos el bucle para generar los eventos \n",
    "for _ in range(N):\n",
    "    e = gen_event()\n",
    "    (out_dir/f\"{e['order_id']}.json\").write_text(json.dumps(e))\n",
    "print(f\"✅ Generados {N} eventos en {out_dir.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90c73242-907f-462c-b435-a435b021601b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PASO 6: Leer los JSONs y crear DataFrame Spark\n",
    "files   = list(out_dir.glob(\"*.json\"))\n",
    "events  = [json.loads(p.read_text()) for p in files]\n",
    "df_raw  = spark.createDataFrame(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e90766f-79a0-418d-bbee-ae035c91457f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PASO 7: Geo‑join para calcular 'district'  \n",
    "from shapely.geometry import Point\n",
    "\n",
    "# 1) Convertir df_raw a pandas para hacer spatial join\n",
    "pdf = df_raw.toPandas()\n",
    "pdf = df_raw.toPandas().drop(columns=[\"neighborhood\"])\n",
    "\n",
    "# 2) Crear GeoDataFrame puntual con lat/lon\n",
    "pdf[\"geometry\"] = pdf.apply(lambda r: Point(r.longitude, r.latitude), axis=1)\n",
    "gpdf = gpd.GeoDataFrame(pdf, geometry=\"geometry\", crs=gdf_neigh.crs)\n",
    "\n",
    "# 3) Spatial join: cada punto recibe el polígono que lo contiene\n",
    "#    Suponemos gdf_neigh tiene columna 'NOMBRE' con el barrio\n",
    "gpdf = gpd.sjoin(gpdf, gdf_neigh[[\"IDENTIFICACION\",\"NOMBRE\", \"geometry\"]], how=\"left\", predicate=\"within\")\n",
    "\n",
    "# 4) Renombrar la columna resultante y limpiar índices\n",
    "# gpdf = gpdf.rename(columns={\"IDENTIFICACION\": \"district\", \"NOMBRE\": \"neighborhood\"}).drop(columns=[\"index_right\"])\n",
    "gpdf = gpdf.rename(columns={\"IDENTIFICACION\": \"neighborhood\", \"NOMBRE\": \"district\"}).drop(columns=[\"index_right\"])\n",
    "\n",
    "\n",
    "# 5) Volver a Spark\n",
    "df_raw = spark.createDataFrame(gpdf.drop(columns=\"geometry\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48148cf7-e6e8-4ca7-819b-d853bcb22c8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PASO 8: Transformar df_raw al esquema Bronze\n",
    "from pyspark.sql.functions import (\n",
    "    to_timestamp, date_format,\n",
    "    year, month, dayofmonth,\n",
    "    hour, minute, second\n",
    ")\n",
    "\n",
    "df_bronze = (\n",
    "    df_raw\n",
    "      # 1) Parsear timestamp\n",
    "      .withColumn(\"event_ts\", to_timestamp(\"date\", \"dd/MM/yyyy HH:mm:ss\"))\n",
    "      # 2) Partición diaria en formato ddMMyyyy\n",
    "      .withColumn(\"partition_date\", date_format(\"event_ts\", \"ddMMyyyy\"))\n",
    "      # 3) Desglosar fecha/hora\n",
    "      .withColumn(\"event_year\",   year(\"event_ts\"))\n",
    "      .withColumn(\"event_month\",  month(\"event_ts\"))\n",
    "      .withColumn(\"event_day\",    dayofmonth(\"event_ts\"))\n",
    "      .withColumn(\"event_hour\",   hour(\"event_ts\"))\n",
    "      .withColumn(\"event_minute\", minute(\"event_ts\"))\n",
    "      .withColumn(\"event_second\", second(\"event_ts\"))\n",
    "      # 4) Renombrar/seleccionar columnas según spec\n",
    "      .select(\n",
    "         \"partition_date\",\n",
    "         \"order_id\",\n",
    "         \"neighborhood\",\n",
    "         \"customer_id\",\n",
    "         \"employee_id\",\n",
    "         \"event_ts\",\n",
    "         \"event_year\",\"event_month\",\"event_day\",\n",
    "         \"event_hour\",\"event_minute\",\"event_second\",\n",
    "         \"latitude\",\"longitude\",\n",
    "         \"district\",\n",
    "         \"quantity_products\"\n",
    "      )\n",
    ")\n",
    "\n",
    "# Inspección rápida del resultado\n",
    "# display(df_bronze.limit(5))\n",
    "# df_bronze.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c251bb52-cbc0-4071-9166-ef5d7d20cff0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "# Limpiar la carpeta sim_events\n",
    "rm -r /Workspace/Users/danielale22rojas@gmail.com/medellin-bigdata-poc/data/sim_events/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "287a15db-a5ba-4420-afea-eed166fb97ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Celda X: Crear el schema de prueba\n",
    "CREATE DATABASE IF NOT EXISTS poctesting;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bafe8abb-a7a6-40c6-b02e-421077a42d8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PASO 9: Persistir en Delta como managed table\n",
    "# Si la tabla no existe, la crea; si existe, hace append.\n",
    "\n",
    "# 1) Guardar como tabla delta en el metastore\n",
    "(\n",
    "  df_bronze\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"append\")\n",
    "    .saveAsTable(\"poctesting.bronze_events\")\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "geopandas",
     "pyarrow",
     "numpy==1.24.4",
     "pandas==2.0.3",
     "scipy==1.11.1"
    ],
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7606693410404173,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01_simulation_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
